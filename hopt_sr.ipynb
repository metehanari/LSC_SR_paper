{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdb7296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\Lenovo\\Desktop\\24-25 bahar\\ADL\\ADL_project\\df_last_encoded.csv\")  # sen zaten yüklüyorsan atla\n",
    "\n",
    "# 'designation' veya ilgili kolonun adını bul\n",
    "designation_col = None\n",
    "for cname in df.columns:\n",
    "    if 'designation' in cname.lower() or 'mat' in cname.lower():\n",
    "        designation_col = cname\n",
    "        break\n",
    "\n",
    "if designation_col is None:\n",
    "    raise ValueError(\"Designation/mat0/mat1 kolonu bulunamadı!\")\n",
    "\n",
    "# Eğer string ise label encode et\n",
    "if df[designation_col].dtype == 'object' or str(df[designation_col].dtype).startswith('str'):\n",
    "    le = LabelEncoder()\n",
    "    df[designation_col + '_label'] = le.fit_transform(df[designation_col])\n",
    "    designation_feat = designation_col + '_label'\n",
    "else:\n",
    "    designation_feat = designation_col\n",
    "\n",
    "# Hedefler\n",
    "feature_cols = [col for col in df.columns if col not in ['n_opt', 'pce', 'hopt (%)', 'PCE (%)']]\n",
    "if designation_feat not in feature_cols:\n",
    "    feature_cols.append(designation_feat)  # Designation'ı featurelara ekle\n",
    "X = df[feature_cols]\n",
    "y_nopt = df['hopt (%)']\n",
    "\n",
    "# Son 30 satırı test olarak ayır\n",
    "X_train, X_test = X.iloc[:-30, :], X.iloc[-30:, :]\n",
    "y_train, y_test = y_nopt.iloc[:-30], y_nopt.iloc[-30:]\n",
    "\n",
    "# Sütun isimlerini sırayla X0, X1,... olarak göster\n",
    "for i, col in enumerate(feature_cols):\n",
    "    print(f\"X{i}: {col}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c02f236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from gplearn.genetic import SymbolicRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def objective(trial):\n",
    "    p_crossover        = trial.suggest_float('p_crossover', 0.5, 0.75)\n",
    "    p_subtree_mutation = trial.suggest_float('p_subtree_mutation', 0.05, 0.12)\n",
    "    p_hoist_mutation   = trial.suggest_float('p_hoist_mutation', 0.01, 0.07)\n",
    "    p_point_mutation   = trial.suggest_float('p_point_mutation', 0.05, 0.12)\n",
    "    if (p_crossover + p_subtree_mutation + p_hoist_mutation + p_point_mutation) > 1.0:\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    sr = SymbolicRegressor(\n",
    "        population_size=trial.suggest_int('population_size', 800, 10000, step=200),\n",
    "        generations=trial.suggest_int('generations', 10, 100, step=5),\n",
    "        stopping_criteria=0.001,\n",
    "        p_crossover=p_crossover,\n",
    "        p_subtree_mutation=p_subtree_mutation,\n",
    "        p_hoist_mutation=p_hoist_mutation,\n",
    "        p_point_mutation=p_point_mutation,\n",
    "        max_samples=trial.suggest_float('max_samples', 0.8, 1.0),\n",
    "        parsimony_coefficient=trial.suggest_float('parsimony_coefficient', 0.001, 0.03, log=True),\n",
    "        function_set=['add', 'sub', 'mul', 'div', 'sin', 'cos','sqrt','log'],  # hızlı prototip için sade set!\n",
    "        metric='mse',\n",
    "        init_depth=trial.suggest_categorical('init_depth', [(2,5), (3,6), (2,6)]),\n",
    "        init_method=trial.suggest_categorical('init_method', ['half and half', 'grow']),\n",
    "        const_range=None,\n",
    "        verbose=0,\n",
    "        random_state=42\n",
    "    )\n",
    "    sr.fit(X_train, y_train)\n",
    "    y_pred = sr.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse  # minimize\n",
    "\n",
    "# HIZLI OPTIMIZASYON (düşük trial)\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=80, show_progress_bar=True)  # n_trials: 5-10 arası hızlı sonuç\n",
    "\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# EN İYİ PARAMETRELERLE MODELİ TEKRAR EĞİT\n",
    "best_params = study.best_params\n",
    "\n",
    "sr = SymbolicRegressor(\n",
    "    population_size=best_params['population_size'],\n",
    "    generations=best_params['generations'],\n",
    "    stopping_criteria=0.001,\n",
    "    p_crossover=best_params['p_crossover'],\n",
    "    p_subtree_mutation=best_params['p_subtree_mutation'],\n",
    "    p_hoist_mutation=best_params['p_hoist_mutation'],\n",
    "    p_point_mutation=best_params['p_point_mutation'],\n",
    "    max_samples=best_params['max_samples'],\n",
    "    parsimony_coefficient=best_params['parsimony_coefficient'],\n",
    "    function_set=['add', 'sub', 'mul', 'div','sin','cos','log','sqrt'],  # yukarıdakiyle aynı set\n",
    "    metric='mse',\n",
    "    init_depth=best_params['init_depth'],\n",
    "    init_method=best_params['init_method'],\n",
    "    const_range=None,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "sr.fit(X_train, y_train)\n",
    "\n",
    "# Sonra sr ile tüm tahmin ve analiz işlemlerini yapabilirsin:\n",
    "# y_pred_train = sr.predict(X_train)\n",
    "# y_pred_test  = sr.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf33bf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optunasız GA\n",
    "\"\"\"from gplearn.genetic import SymbolicRegressor\n",
    "\n",
    "sr = SymbolicRegressor(\n",
    "    population_size=10000,\n",
    "    generations=100,\n",
    "    stopping_criteria=0.001,\n",
    "    p_crossover=0.7,\n",
    "    p_subtree_mutation=0.1,\n",
    "    p_hoist_mutation=0.05,\n",
    "    p_point_mutation=0.1,\n",
    "    max_samples=0.95,\n",
    "    parsimony_coefficient=0.003,\n",
    "    function_set=['add', 'sub', 'mul', 'div', 'sqrt', 'log', 'sin', 'cos'],\n",
    "    metric='mse',\n",
    "    init_depth=(3, 8),\n",
    "    init_method='half and half',\n",
    "    const_range=None,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "sr.fit(X_train, y_train)\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae14db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gplearn.genetic import SymbolicRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# ... (optuna ile hyperparam tuning ve training kodun aynen)\n",
    "\n",
    "# Eğitim sonrası\n",
    "print(\"Bulunan formül:\", sr._program)\n",
    "\n",
    "# Formülde Xn (designation’ın indexi) var mı?\n",
    "designation_idx = feature_cols.index(designation_feat)\n",
    "if f\"X{designation_idx}\" in str(sr._program):\n",
    "    print(f\"Formülde designation (X{designation_idx}) KULLANILDI!\")\n",
    "else:\n",
    "    print(\"Formülde designation YOK! (Model bunu matematiksel olarak gerek görmedi.)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ebb4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bulunan matematiksel formül\n",
    "print(\"n_opt için bulunan formül:\")\n",
    "print(sr._program)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6857bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "y_pred_train = sr.predict(X_train)\n",
    "y_pred_test = sr.predict(X_test)\n",
    "\n",
    "# Metrikler\n",
    "print(\"Train R2:\", r2_score(y_train, y_pred_train))\n",
    "print(\"Test R2 :\", r2_score(y_test, y_pred_test))\n",
    "print(\"Test MSE:\", mean_squared_error(y_test, y_pred_test))\n",
    "print(\"Test MAE:\", mean_absolute_error(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261ace0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = cross_val_score(sr, X_train, y_train, cv=5, scoring='r2')\n",
    "print(\"5-Fold CV R2 Skorları (Train Seti):\", cv_scores)\n",
    "print(\"CV Ortalama R2:\", np.mean(cv_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6272ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Symbolic Regression - Comprehensive Analysis\n",
    "Optik Malzeme n_opt Tahmini - Görselleştirme ve Analiz\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from collections import Counter\n",
    "\n",
    "# Seaborn style ayarları\n",
    "sns.set_theme(style=\"whitegrid\", font_scale=1.25, rc={\"axes.labelweight\":\"bold\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549eb62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# DATA PREPARATION & UTILITY FUNCTIONS\n",
    "# ====================================\n",
    "\n",
    "def to_numpy(X):\n",
    "    \"\"\"Convert to numpy array safely\"\"\"\n",
    "    return X.values if hasattr(X, \"values\") else np.asarray(X)\n",
    "\n",
    "def get_feature_names(X):\n",
    "    \"\"\"Extract feature names\"\"\"\n",
    "    if hasattr(X, \"columns\"):\n",
    "        return list(X.columns)\n",
    "    X_np = to_numpy(X)\n",
    "    return [f\"X{i}\" for i in range(X_np.shape[1])]\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculate all regression metrics\"\"\"\n",
    "    corr, p_value = pearsonr(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    return {\n",
    "        'correlation': corr,\n",
    "        'p_value': p_value,\n",
    "        'r2': r2,\n",
    "        'mse': mse,\n",
    "        'mae': mae\n",
    "    }\n",
    "\n",
    "# Veri hazırlığı\n",
    "y_train_plot = pd.Series(y_train).reset_index(drop=True)\n",
    "y_pred_train_plot = pd.Series(y_pred_train).reset_index(drop=True)\n",
    "y_test_plot = pd.Series(y_test).reset_index(drop=True)\n",
    "y_pred_test_plot = pd.Series(y_pred_test).reset_index(drop=True)\n",
    "\n",
    "Xtr = to_numpy(X_train)\n",
    "Xte = to_numpy(X_test)\n",
    "feat_names = get_feature_names(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd63f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# VISUALIZATION FUNCTIONS\n",
    "# ====================================\n",
    "\n",
    "def plot_scatter_comparison(y_train, y_pred_train, y_test, y_pred_test):\n",
    "    \"\"\"Combined train-test scatter plot\"\"\"\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    # Train scatter\n",
    "    sns.scatterplot(x=y_train, y=y_pred_train, s=65, color=\"#3288bd\", \n",
    "                   edgecolor='k', ax=ax[0])\n",
    "    ax[0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], \n",
    "               'r--', lw=2, label=\"Identity (y = x)\")\n",
    "    ax[0].set_xlabel(\"Actual $n_{opt}$ (Train Set)\")\n",
    "    ax[0].set_ylabel(\"Predicted $n_{opt}$ (Train Set)\")\n",
    "    ax[0].set_title(\"Train Set: Actual vs. Predicted\")\n",
    "    ax[0].legend()\n",
    "    ax[0].grid(True, linestyle=':', alpha=0.7)\n",
    "    \n",
    "    # Test scatter\n",
    "    sns.scatterplot(x=y_test, y=y_pred_test, s=65, color=\"#e08214\", \n",
    "                   edgecolor='k', ax=ax[1])\n",
    "    ax[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "               'r--', lw=2, label=\"Identity (y = x)\")\n",
    "    ax[1].set_xlabel(\"Actual $n_{opt}$ (Test Set)\")\n",
    "    ax[1].set_ylabel(\"Predicted $n_{opt}$ (Test Set)\")\n",
    "    ax[1].set_title(\"Test Set: Actual vs. Predicted\")\n",
    "    ax[1].legend()\n",
    "    ax[1].grid(True, linestyle=':', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_residual_analysis(y_test, y_pred_test):\n",
    "    \"\"\"Residual plot for test set\"\"\"\n",
    "    residuals = y_test - y_pred_test\n",
    "    plt.figure(figsize=(8, 4.5))\n",
    "    sns.scatterplot(x=y_pred_test, y=residuals, s=95, color=\"#e08214\", edgecolor='k')\n",
    "    plt.axhline(0, color='red', linestyle='--', lw=2, label=\"Zero Error\")\n",
    "    plt.xlabel(\"Predicted $n_{opt}$ (Test Set)\")\n",
    "    plt.ylabel(\"Residual (Actual - Predicted)\")\n",
    "    plt.title(\"Test Set: Residual Analysis\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_time_series_comparison(y_test, y_pred_test):\n",
    "    \"\"\"Time series comparison plot\"\"\"\n",
    "    plt.figure(figsize=(13, 5))\n",
    "    sns.lineplot(x=np.arange(len(y_test)), y=y_test, label='Actual $n_{opt}$', \n",
    "                lw=2.5, color='#1f77b4')\n",
    "    sns.lineplot(x=np.arange(len(y_pred_test)), y=y_pred_test, \n",
    "                label='Predicted $n_{opt}$', lw=2.5, color='#ff7f0e')\n",
    "    plt.fill_between(np.arange(len(y_test)), y_test, y_pred_test, \n",
    "                     color='grey', alpha=0.18, label='Error Area')\n",
    "    plt.xlabel(\"Sample Index (Test Set)\")\n",
    "    plt.ylabel(\"$n_{opt}$ Value\")\n",
    "    plt.title(\"Test Set: Actual vs Predicted Comparison\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_error_histogram(y_test, y_pred_test):\n",
    "    \"\"\"Absolute error histogram\"\"\"\n",
    "    abs_error = np.abs(y_test - y_pred_test)\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    sns.histplot(abs_error, bins=8, kde=True, color='#5dade2', \n",
    "                edgecolor='k', alpha=0.9)\n",
    "    plt.xlabel(\"Absolute Error\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Test Set: Absolute Error Distribution\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2a3ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# METRICS CALCULATION & REPORTING\n",
    "# ====================================\n",
    "\n",
    "def print_metrics(y_train, y_pred_train, y_test, y_pred_test):\n",
    "    \"\"\"Calculate and print all metrics\"\"\"\n",
    "    \n",
    "    train_metrics = calculate_metrics(y_train, y_pred_train)\n",
    "    test_metrics = calculate_metrics(y_test, y_pred_test)\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"SYMBOLIC REGRESSION PERFORMANCE METRICS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(\"\\nTRAIN SET METRICS:\")\n",
    "    print(f\"Pearson correlation: {train_metrics['correlation']:.4f} (p-value: {train_metrics['p_value']:.2e})\")\n",
    "    print(f\"R² score           : {train_metrics['r2']:.4f}\")\n",
    "    print(f\"MSE                : {train_metrics['mse']:.4f}\")\n",
    "    print(f\"MAE                : {train_metrics['mae']:.4f}\")\n",
    "    \n",
    "    print(\"\\nTEST SET METRICS:\")\n",
    "    print(f\"Pearson correlation: {test_metrics['correlation']:.4f} (p-value: {test_metrics['p_value']:.2e})\")\n",
    "    print(f\"R² score           : {test_metrics['r2']:.4f}\")\n",
    "    print(f\"MSE                : {test_metrics['mse']:.4f}\")\n",
    "    print(f\"MAE                : {test_metrics['mae']:.4f}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    return train_metrics, test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5d232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# ADVANCED ANALYSIS FUNCTIONS\n",
    "# ====================================\n",
    "\n",
    "def numerical_partials(estimator, X, eps=1e-4):\n",
    "    \"\"\"Numerical partial derivatives using central difference\"\"\"\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    n, d = X.shape\n",
    "    grads = np.zeros((n, d), dtype=float)\n",
    "    \n",
    "    for j in range(d):\n",
    "        Xp = X.copy()\n",
    "        Xm = X.copy()\n",
    "        h = eps * (np.abs(X[:, j]) + 1.0)\n",
    "        Xp[:, j] += h\n",
    "        Xm[:, j] -= h\n",
    "        yp = estimator.predict(Xp)\n",
    "        ym = estimator.predict(Xm)\n",
    "        grads[:, j] = (yp - ym) / (2.0 * h)\n",
    "    \n",
    "    return grads\n",
    "\n",
    "def plot_sensitivity_analysis(estimator, X_train, feat_names, top_k=10):\n",
    "    \"\"\"Feature sensitivity analysis using partial derivatives\"\"\"\n",
    "    \n",
    "    grads_train = numerical_partials(estimator, X_train, eps=1e-4)\n",
    "    mean_abs_grad = np.mean(np.abs(grads_train), axis=0)\n",
    "    order = np.argsort(-mean_abs_grad)\n",
    "    topk = min(top_k, len(feat_names))\n",
    "    top_idx = order[:topk]\n",
    "    \n",
    "    # Bar plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.bar([feat_names[i] for i in top_idx], mean_abs_grad[top_idx])\n",
    "    plt.ylabel(\"Mean |∂ŷ/∂x|\")\n",
    "    plt.title(f\"Feature Sensitivity (Top {topk})\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    \n",
    "    # Heatmap\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(grads_train[:, top_idx].T, aspect='auto', interpolation='nearest')\n",
    "    plt.colorbar(label=\"∂ŷ/∂x\")\n",
    "    plt.yticks(range(topk), [feat_names[i] for i in top_idx])\n",
    "    plt.xlabel(\"Sample Index\")\n",
    "    plt.title(\"Sensitivity Heatmap\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return top_idx, mean_abs_grad\n",
    "\n",
    "def pdp_1d(estimator, X, j, grid_resolution=40, q_low=0.01, q_high=0.99):\n",
    "    \"\"\"Partial Dependence Plot for single feature\"\"\"\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    xj = X[:, j]\n",
    "    lo = np.quantile(xj, q_low)\n",
    "    hi = np.quantile(xj, q_high)\n",
    "    grid = np.linspace(lo, hi, grid_resolution)\n",
    "    \n",
    "    pdp_vals = []\n",
    "    for v in grid:\n",
    "        Xtmp = X.copy()\n",
    "        Xtmp[:, j] = v\n",
    "        yhat = estimator.predict(Xtmp)\n",
    "        pdp_vals.append(yhat.mean())\n",
    "    \n",
    "    return grid, np.array(pdp_vals)\n",
    "\n",
    "def plot_pdp_analysis(estimator, X_train, feat_names, top_indices, n_features=3):\n",
    "    \"\"\"Plot PDP for top features\"\"\"\n",
    "    n_plot = min(n_features, len(top_indices))\n",
    "    \n",
    "    fig, axes = plt.subplots(1, n_plot, figsize=(5*n_plot, 4))\n",
    "    if n_plot == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, j in enumerate(top_indices[:n_plot]):\n",
    "        grid, pdp_vals = pdp_1d(estimator, X_train, j)\n",
    "        axes[i].plot(grid, pdp_vals, lw=2, color='#2E86AB')\n",
    "        axes[i].set_xlabel(feat_names[j])\n",
    "        axes[i].set_ylabel(\"E[ŷ | x_j]\")\n",
    "        axes[i].set_title(f\"PDP: {feat_names[j]}\")\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0870e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# BOOTSTRAP STABILITY ANALYSIS\n",
    "# ====================================\n",
    "\n",
    "def clone_sr_with_params(base_sr, random_state):\n",
    "    \"\"\"Clone SR estimator with new random state\"\"\"\n",
    "    params = base_sr.get_params(deep=True)\n",
    "    params['random_state'] = random_state\n",
    "    params['verbose'] = 0\n",
    "    return type(base_sr)(**params)\n",
    "\n",
    "def bootstrap_stability_analysis(estimator, X_train, y_train, X_test, y_test, \n",
    "                                n_bootstrap=30, random_seed=123):\n",
    "    \"\"\"Bootstrap analysis for model stability\"\"\"\n",
    "    \n",
    "    expr_list = []\n",
    "    complexities = []\n",
    "    Yhat_te = []\n",
    "    \n",
    "    rng = np.random.default_rng(random_seed)\n",
    "    \n",
    "    print(f\"Running {n_bootstrap} bootstrap iterations...\")\n",
    "    \n",
    "    for b in range(n_bootstrap):\n",
    "        idx = rng.integers(0, X_train.shape[0], size=X_train.shape[0])\n",
    "        Xb = X_train[idx]\n",
    "        yb = to_numpy(y_train)[idx]\n",
    "        \n",
    "        sr_b = clone_sr_with_params(estimator, random_state=42 + b)\n",
    "        sr_b.fit(Xb, yb)\n",
    "        \n",
    "        prog = getattr(sr_b, \"_program\", None)\n",
    "        expr = str(prog) if prog is not None else None\n",
    "        expr_list.append(expr)\n",
    "        \n",
    "        length = getattr(prog, \"length_\", None)\n",
    "        depth = getattr(prog, \"depth_\", None)\n",
    "        complexities.append({\"length\": length, \"depth\": depth})\n",
    "        \n",
    "        yhat = sr_b.predict(X_test)\n",
    "        Yhat_te.append(yhat)\n",
    "        \n",
    "        if (b + 1) % 10 == 0:\n",
    "            print(f\"  Completed {b + 1}/{n_bootstrap}\")\n",
    "    \n",
    "    Yhat_te = np.vstack(Yhat_te)\n",
    "    return expr_list, complexities, Yhat_te\n",
    "\n",
    "def plot_bootstrap_results(y_test, Yhat_te, expr_list, complexities):\n",
    "    \"\"\"Plot bootstrap analysis results\"\"\"\n",
    "    \n",
    "    # Prediction bands\n",
    "    low = np.percentile(Yhat_te, 5, axis=0)\n",
    "    med = np.percentile(Yhat_te, 50, axis=0)\n",
    "    high = np.percentile(Yhat_te, 95, axis=0)\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(range(len(y_test)), to_numpy(y_test), label=\"Actual\", lw=2, color='#1f77b4')\n",
    "    plt.plot(range(len(med)), med, label=\"Bootstrap Median\", lw=2, color='#ff7f0e')\n",
    "    plt.fill_between(range(len(low)), low, high, alpha=0.25, label=\"5%-95% Band\", color='#ff7f0e')\n",
    "    plt.xlabel(\"Sample Index (Test)\")\n",
    "    plt.ylabel(\"$n_{opt}$\")\n",
    "    plt.title(\"Bootstrap Prediction Uncertainty\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Expression frequency\n",
    "    ctr = Counter(expr_list)\n",
    "    print(\"\\nMost frequent expressions:\")\n",
    "    for expr, cnt in ctr.most_common(5):\n",
    "        print(f\"{cnt:>3}x  {expr}\")\n",
    "    \n",
    "    # Complexity distribution\n",
    "    lengths = [c[\"length\"] for c in complexities if c[\"length\"] is not None]\n",
    "    depths = [c[\"depth\"] for c in complexities if c[\"depth\"] is not None]\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(lengths, bins=10, edgecolor='k', alpha=0.7, color='#5dade2')\n",
    "    plt.xlabel(\"Program Length\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Complexity Distribution (Length)\")\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(depths, bins=10, edgecolor='k', alpha=0.7, color='#e08214')\n",
    "    plt.xlabel(\"Program Depth\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Complexity Distribution (Depth)\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823ea8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# MAIN EXECUTION\n",
    "# ====================================\n",
    "\n",
    "def run_comprehensive_analysis():\n",
    "    \"\"\"Run complete SR analysis pipeline\"\"\"\n",
    "    \n",
    "    print(\"Starting Comprehensive Symbolic Regression Analysis...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 1. Basic Visualizations\n",
    "    print(\"\\n1. Creating basic visualizations...\")\n",
    "    plot_scatter_comparison(y_train_plot, y_pred_train_plot, y_test_plot, y_pred_test_plot)\n",
    "    plot_residual_analysis(y_test_plot, y_pred_test_plot)\n",
    "    plot_time_series_comparison(y_test_plot, y_pred_test_plot)\n",
    "    plot_error_histogram(y_test_plot, y_pred_test_plot)\n",
    "    \n",
    "    # 2. Metrics Calculation\n",
    "    print(\"\\n2. Calculating metrics...\")\n",
    "    train_metrics, test_metrics = print_metrics(y_train_plot, y_pred_train_plot, y_test_plot, y_pred_test_plot)\n",
    "    \n",
    "    # 3. Feature Sensitivity Analysis\n",
    "    print(\"\\n3. Running feature sensitivity analysis...\")\n",
    "    top_indices, sensitivities = plot_sensitivity_analysis(sr, Xtr, feat_names)\n",
    "    \n",
    "    # 4. Partial Dependence Plots\n",
    "    print(\"\\n4. Creating partial dependence plots...\")\n",
    "    plot_pdp_analysis(sr, Xtr, feat_names, top_indices)\n",
    "    \n",
    "    # 5. Bootstrap Stability Analysis\n",
    "    print(\"\\n5. Running bootstrap stability analysis...\")\n",
    "    expr_list, complexities, Yhat_te = bootstrap_stability_analysis(\n",
    "        sr, Xtr, y_train, Xte, y_test, n_bootstrap=30\n",
    "    )\n",
    "    plot_bootstrap_results(y_test, Yhat_te, expr_list, complexities)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Comprehensive analysis completed!\")\n",
    "    \n",
    "    return {\n",
    "        'train_metrics': train_metrics,\n",
    "        'test_metrics': test_metrics,\n",
    "        'top_features': top_indices,\n",
    "        'sensitivities': sensitivities,\n",
    "        'bootstrap_results': (expr_list, complexities, Yhat_te)\n",
    "    }\n",
    "\n",
    "# Ana çalıştırma\n",
    "if __name__ == \"__main__\":\n",
    "    results = run_comprehensive_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9279e1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== INFERENCE TIME & FIGURE OF MERIT (ONLY THIS PART) ====\n",
    "import time\n",
    "import gc\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "def _fmt_seconds(s):\n",
    "    # İnsan gibi format: ns/µs/ms/s aralığında otomatik\n",
    "    if s < 1e-6:\n",
    "        return f\"{s*1e9:.1f} ns\"\n",
    "    if s < 1e-3:\n",
    "        return f\"{s*1e6:.1f} µs\"\n",
    "    if s < 1:\n",
    "        return f\"{s*1e3:.2f} ms\"\n",
    "    return f\"{s:.3f} s\"\n",
    "\n",
    "def measure_inference_speed(estimator, X,\n",
    "                            warmup=50,\n",
    "                            repeats_single=1000,\n",
    "                            batch_sizes=(1, 8, 32, 128, None),\n",
    "                            random_state=42):\n",
    "    \"\"\"\n",
    "    batch_sizes:\n",
    "      - 1: tek örnek gecikmesi\n",
    "      - sayılar: mini-batch gecikmesi (N örnek bir seferde)\n",
    "      - None: X'in tamamı (full-batch)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    X_np = X.values if hasattr(X, \"values\") else np.asarray(X)\n",
    "    n = X_np.shape[0]\n",
    "\n",
    "    # Model karmaşıklığı (gplearn)\n",
    "    prog = getattr(estimator, \"_program\", None)\n",
    "    prog_len = getattr(prog, \"length_\", None)\n",
    "    prog_depth = getattr(prog, \"depth_\", None)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*72)\n",
    "    print(\"INFERENCE SPEED & FIGURE OF MERIT\")\n",
    "    print(\"=\"*72)\n",
    "    print(f\"Python: {sys.version.split()[0]} | NumPy: {np.__version__}\")\n",
    "    if prog is not None:\n",
    "        print(f\"Expression length (nodes): {prog_len}, depth: {prog_depth}\")\n",
    "        # İstersen formülü de göster:\n",
    "        # print(f\"Expression: {prog}\")\n",
    "    else:\n",
    "        print(\"Warning: gplearn program objesi bulunamadı.\")\n",
    "\n",
    "    # --- Warmup (JIT yok ama cache ve memory ayarı için faydalı) ---\n",
    "    if n > 0:\n",
    "        idx_warm = rng.integers(0, n, size=min(warmup, max(1, n)))\n",
    "        for i in idx_warm:\n",
    "            _ = estimator.predict(X_np[i:i+1])\n",
    "        _ = estimator.predict(X_np[: min(n, 256)])  # küçük bir batch warmup\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for bs in batch_sizes:\n",
    "        if bs == 1:\n",
    "            # Tek örnek gecikmesi (repeats_single kez farklı örneklerle)\n",
    "            times = []\n",
    "            gc.collect()\n",
    "            for _ in range(repeats_single):\n",
    "                i = rng.integers(0, n)\n",
    "                x1 = X_np[i:i+1]\n",
    "                t0 = time.perf_counter()\n",
    "                _ = estimator.predict(x1)\n",
    "                t1 = time.perf_counter()\n",
    "                times.append(t1 - t0)\n",
    "            times = np.array(times)\n",
    "            mean_t = float(times.mean())\n",
    "            median_t = float(np.median(times))\n",
    "            p90 = float(np.percentile(times, 90))\n",
    "            p99 = float(np.percentile(times, 99))\n",
    "            thr = 1.0 / mean_t  # samples/sec\n",
    "\n",
    "            results.append({\n",
    "                \"batch_size\": 1,\n",
    "                \"mean_latency_s\": mean_t,\n",
    "                \"median_latency_s\": median_t,\n",
    "                \"p90_latency_s\": p90,\n",
    "                \"p99_latency_s\": p99,\n",
    "                \"throughput_sps\": thr\n",
    "            })\n",
    "\n",
    "            print(\"\\n--- Single-sample latency (batch=1) ---\")\n",
    "            print(f\"Mean   : {_fmt_seconds(mean_t)}  | Throughput: {thr:,.0f} samples/s\")\n",
    "            print(f\"Median : {_fmt_seconds(median_t)}\")\n",
    "            print(f\"P90    : {_fmt_seconds(p90)}\")\n",
    "            print(f\"P99    : {_fmt_seconds(p99)}\")\n",
    "\n",
    "        else:\n",
    "            # Mini-batch veya full-batch\n",
    "            if bs is None:\n",
    "                # full-batch: tüm X bir kerede\n",
    "                bs_eff = n\n",
    "                if bs_eff == 0:\n",
    "                    print(\"\\nFull-batch ölçümü atlandı (X boş).\")\n",
    "                    continue\n",
    "                batch = X_np\n",
    "                label = \"FULL-BATCH\"\n",
    "            else:\n",
    "                bs_eff = min(bs, n) if n > 0 else 0\n",
    "                if bs_eff == 0:\n",
    "                    print(f\"\\nBatch={bs} ölçümü atlandı (X boş).\")\n",
    "                    continue\n",
    "                idx = rng.integers(0, n, size=bs_eff)\n",
    "                batch = X_np[idx]\n",
    "                label = f\"BATCH={bs_eff}\"\n",
    "\n",
    "            # Birkaç tekrar ile istatistik\n",
    "            repeats = 50 if bs_eff >= 32 else 100\n",
    "            times = []\n",
    "            gc.collect()\n",
    "            for _ in range(repeats):\n",
    "                t0 = time.perf_counter()\n",
    "                _ = estimator.predict(batch)\n",
    "                t1 = time.perf_counter()\n",
    "                times.append(t1 - t0)\n",
    "            times = np.array(times)\n",
    "            mean_t = float(times.mean())\n",
    "            median_t = float(np.median(times))\n",
    "            p90 = float(np.percentile(times, 90))\n",
    "            p99 = float(np.percentile(times, 99))\n",
    "            thr = bs_eff / mean_t  # samples/sec\n",
    "\n",
    "            results.append({\n",
    "                \"batch_size\": int(bs_eff),\n",
    "                \"mean_latency_s\": mean_t,\n",
    "                \"median_latency_s\": median_t,\n",
    "                \"p90_latency_s\": p90,\n",
    "                \"p99_latency_s\": p99,\n",
    "                \"throughput_sps\": thr\n",
    "            })\n",
    "\n",
    "            print(f\"\\n--- {label} latency ---\")\n",
    "            print(f\"Mean   : {_fmt_seconds(mean_t)}  | Eff. batch: {bs_eff}  | Throughput: {thr:,.0f} samples/s\")\n",
    "            print(f\"Median : {_fmt_seconds(median_t)}\")\n",
    "            print(f\"P90    : {_fmt_seconds(p90)}\")\n",
    "            print(f\"P99    : {_fmt_seconds(p99)}\")\n",
    "\n",
    "    # Özet FoM (figure of merit)\n",
    "    # - Single-sample median latency\n",
    "    # - P99 latency\n",
    "    # - Best throughput (max over all batches)\n",
    "    one = next((r for r in results if r[\"batch_size\"] == 1), None)\n",
    "    best_thr = max(results, key=lambda r: r[\"throughput_sps\"]) if results else None\n",
    "\n",
    "    print(\"\\n\" + \"-\"*72)\n",
    "    print(\"FIGURE OF MERIT (FoM)\")\n",
    "    if one:\n",
    "        print(f\"Single-sample median latency : {_fmt_seconds(one['median_latency_s'])}\")\n",
    "        print(f\"Single-sample P99 latency    : {_fmt_seconds(one['p99_latency_s'])}\")\n",
    "    if best_thr:\n",
    "        print(f\"Max throughput               : {best_thr['throughput_sps']:,.0f} samples/s \"\n",
    "              f\"(batch={best_thr['batch_size']})\")\n",
    "    if prog is not None:\n",
    "        print(f\"Expression complexity        : length={prog_len}, depth={prog_depth}\")\n",
    "    print(\"-\"*72 + \"\\n\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# ÇALIŞTIR\n",
    "_ = measure_inference_speed(sr, X_test)\n",
    "# İstersen eğitim seti için de:\n",
    "# _ = measure_inference_speed(sr, X_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
